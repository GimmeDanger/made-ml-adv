{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part-4: EM algorithm\n",
    "\n",
    "Теперь главное: ЧГК — это всё-таки командная игра. Поэтому:\n",
    "* предложите способ учитывать то, что на вопрос отвечают сразу несколько игроков; скорее всего, понадобятся скрытые переменные; не стесняйтесь делать упрощающие предположения, но теперь переменные “игрок X ответил на вопрос Y” при условии данных должны стать зависимыми для игроков одной и той же команды;\n",
    "* разработайте EM-схему для обучения этой модели, реализуйте её в коде;\n",
    "* обучите несколько итераций, убедитесь, что целевые метрики со временем растут (скорее всего, ненамного, но расти должны), выберите лучшую модель, используя целевые метрики.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# source: https://stackoverflow.com/questions/19201290/how-to-save-a-dictionary-to-a-file/32216025\n",
    "def save_obj(obj, name ):\n",
    "    with open('obj/'+ name + '.pkl', 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def load_obj(name ):\n",
    "    with open('obj/' + name + '.pkl', 'rb') as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Решение\n",
    "\n",
    "### M-step\n",
    "* В рамках baseline (part 2) мы научились предсказывать $p(z_{i,j}=1)$ -- вероятность ответил ли игрок i на вопрос j, веса фичей пользователя обученной модели мы интерпретировали как их \"силу\";\n",
    "* Если выбрать $z_{i, j}$ в качестве скрытых переменных, то M-шаг сводится к дообучению модели при заданных $z_(i, j)$, начальные веса совпадают с исходными метками $x_{i,j}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>team_id</th>\n",
       "      <th>player_id</th>\n",
       "      <th>target</th>\n",
       "      <th>question_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>45556</td>\n",
       "      <td>6212</td>\n",
       "      <td>1</td>\n",
       "      <td>4772_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>45556</td>\n",
       "      <td>6212</td>\n",
       "      <td>1</td>\n",
       "      <td>4772_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>45556</td>\n",
       "      <td>6212</td>\n",
       "      <td>1</td>\n",
       "      <td>4772_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>45556</td>\n",
       "      <td>6212</td>\n",
       "      <td>1</td>\n",
       "      <td>4772_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>45556</td>\n",
       "      <td>6212</td>\n",
       "      <td>1</td>\n",
       "      <td>4772_4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   team_id  player_id  target question_id\n",
       "0    45556       6212       1      4772_0\n",
       "1    45556       6212       1      4772_1\n",
       "2    45556       6212       1      4772_2\n",
       "3    45556       6212       1      4772_3\n",
       "4    45556       6212       1      4772_4"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data: describe and computed in part 1\n",
    "n_epoch = 5\n",
    "df_train = pd.read_csv('train.zip')\n",
    "df_train[\"question_id\"] = df_train['tournament_id'].astype(str) + '_' + df_train['question_local_id'].astype(str)\n",
    "df_train = df_train.drop(columns=['tournament_id', 'question_local_id'])\n",
    "X, y = df_train[['player_id', 'question_id']], df_train['target']\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# m-step model: described in part 2\n",
    "\n",
    "feature_generation = ColumnTransformer(\n",
    "    transformers=[('OneHot', OneHotEncoder(), ['player_id', 'question_id'])],\n",
    "    remainder='drop',\n",
    "    sparse_threshold=1\n",
    ")\n",
    "\n",
    "# Замечание: пришлось заменить sklearn::LogisticRegression, тк в ходе выполнения задания\n",
    "# выяснилось, что она плохо работает с небинарными таргетами, поэтому заменил ее на другой регрессор:\n",
    "# https://stackoverflow.com/questions/47663569/how-to-do-regression-as-opposed-to-classification-using-logistic-regression-and\n",
    "pipe = Pipeline(\n",
    "    verbose=True,\n",
    "    steps=[\n",
    "        ('feature_generation', feature_generation),\n",
    "        ('regressor', LinearSVR(loss='squared_epsilon_insensitive'))\n",
    "    ]\n",
    ")\n",
    "\n",
    "def m_step(model, X, y):\n",
    "    model.fit(X, y)\n",
    "    return model, model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_player_weights(X, model):\n",
    "    \"\"\"\n",
    "    сохраняем веса фичей пользователей из обученного классификатора\n",
    "    \"\"\"\n",
    "    player_features_end_pos = X.nunique()['question_id']\n",
    "    player_features_names = model['feature_generation'].get_feature_names()[0:player_features_end_pos]\n",
    "    player_ids = [int(name[11:]) for name in player_features_names]\n",
    "    player_weights = model['regressor'].coef_[0:player_features_end_pos]\n",
    "    player_to_weight = dict(zip(player_ids, player_weights))\n",
    "    return player_to_weight\n",
    "\n",
    "#_, preds = m_step(pipe, X, y)\n",
    "#validate(load_obj('test'), save_player_weights(X, _))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# E-step\n",
    "\n",
    "* Теперь хотим учесть наличие команды, тч $z_{i,j}$ стали зависимыми для игроков одной команды, перейдем к прогнозированию условных вероятностей $p(z_{i,j} = 1)$ -> $p(z_{i,j} = 1 | team_{i, j} = 1)$, где $team_{i, j}$ -- ответила ли команда игрока i на вопрос j;\n",
    "* Предположим, что $$team_{i, j} = 1 \\iff \\exists k \\in team_i : z_{k, j} = 1$$\n",
    "* И наоборот: $$team_{i, j} = 0 \\iff \\forall k \\in team_i : z_{k, j} = 0$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По теореме Байеса имеем:\n",
    "$$\n",
    "    p(z_{i,j}=1|team_{i,j}=1) = \\frac{p(team_{i,j}=1|z_{i,j}=1) p(z_{i,j}=1)}{p(team_{i,j}=1)}\n",
    "$$\n",
    "\n",
    "C учетом предположений имеем:\n",
    "$$\n",
    "    p(z_{i,j}=1|team_{i,j}=1) = \\frac{p(z_{i,j}=1)}{1 - p(team_{i,j}=0)} = \\frac{p(z_{i,j}=1)}{1 - \\Pi_{k \\in team_i} \\left(1 - p(z_{k,j}=1)\\right)}\n",
    "$$\n",
    "\n",
    "С учетом того, что $p(z_{i,j}=1)$ являются результатом M-шага, то формула выше может быть использована для E-шага"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def e_step(df, preds):\n",
    "    df['new_target'] = preds\n",
    "    label_zero_idx = df['target'] == 0\n",
    "    df.loc[label_zero_idx, 'new_target'] = 0\n",
    "    # изменяем только метки для вопросов, на которые команда ответила\n",
    "    # поскольку p(z_ij = 1 | team_ij = 0) = 0 в силу предположений\n",
    "    label_one_idx = df['target'] == 1\n",
    "    e_step_denom = df.loc[label_one_idx].groupby(['team_id', 'question_id'])['new_target']\n",
    "    e_step_denom = e_step_denom.transform(lambda x : 1 - np.prod(1 - x.values))\n",
    "    df.loc[label_one_idx, 'new_target'] = df.loc[label_one_idx, 'new_target'] / e_step_denom\n",
    "    new_y = df['new_target'].fillna(0)\n",
    "    return new_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline]  (step 1 of 2) Processing feature_generation, total=  10.6s\n",
      "[Pipeline] ......... (step 2 of 2) Processing regressor, total= 8.8min\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'i' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-78d6ef340dc4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# initialization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mpipe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0msave_obj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_player_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpipe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf'weights-save-test{i}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'i' is not defined"
     ]
    }
   ],
   "source": [
    "# initialization\n",
    "pipe, preds = m_step(pipe, X, y)\n",
    "#validate(load_obj('test'), save_player_weights(X, pipe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EM-iterations\n",
    "for i in range(n_epoch):\n",
    "    y = e_step(df_train, preds)\n",
    "    pipe, preds = m_step(pipe, X, y)\n",
    "    weights = save_player_weights(X, pipe)\n",
    "    save_obj(weights, f'em_weights_epoch_{i}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation: described in part 3\n",
    "\n",
    "def get_positions_label(tournament):\n",
    "    \"\"\"\n",
    "    позиции команд в турнире (фактические)\n",
    "    \"\"\"\n",
    "    return [team['position'] for team in tournament]\n",
    "\n",
    "\n",
    "def get_position_prediction(tournament, player_to_weight):\n",
    "    \"\"\"\n",
    "    позиции команд в турнире (предсказанные),\n",
    "    ранжируем команды по весу = (сумма весов участников),\n",
    "    есть игрока не было в train -- берем средний вес игрока в трейне\n",
    "    \"\"\"\n",
    "    avg_weight = np.mean([v for v in player_to_weight.values()])\n",
    "    team_rating = []\n",
    "    for idx, team in enumerate(tournament):\n",
    "        weight = 0\n",
    "        for player_info in team['teamMembers']:\n",
    "            p_id = player_info['player']['id']\n",
    "            try:\n",
    "                weight += player_to_weight[p_id]\n",
    "            except:\n",
    "                weight += avg_weight\n",
    "        team_rating.append((idx + 1, weight))\n",
    "    team_rating = sorted(team_rating, key=lambda kv: kv[1], reverse=True)\n",
    "    return [pos for pos, weight in team_rating]\n",
    "\n",
    "\n",
    "def get_score(df_test, player_to_weight, corr):\n",
    "    \"\"\"\n",
    "    среднее значение rank correlation по тестовой выборке\n",
    "    \"\"\"\n",
    "    x = [corr(get_positions_label(t), get_position_prediction(t, player_to_weight)).correlation for t in df_test.values()]\n",
    "    x = np.array(x)\n",
    "    x = x[~np.isnan(x)]\n",
    "    return np.mean(x)\n",
    "\n",
    "def validate(df_test, player_to_weight, corr=None):\n",
    "    if corr is None:\n",
    "        for corr in [('Spearman', stats.spearmanr), ('Kendall ', stats.kendalltau)]:\n",
    "            print(f'Avg {corr[0]} corr value for df = {get_score(df_test, player_to_weight, corr[1])}')\n",
    "    else:\n",
    "        print(f'Avg {corr[0]} corr value for df = {get_score(df_test, player_to_weight, corr[1])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:\n",
      "Avg Spearman corr value for df = 0.7146658849862952\n",
      "Avg Kendall  corr value for df = 0.5675789093491839\n",
      "Epoch 2:\n",
      "Avg Spearman corr value for df = 0.7042747861421622\n",
      "Avg Kendall  corr value for df = 0.5585264301646335\n",
      "Epoch 3:\n",
      "Avg Spearman corr value for df = 0.6980406142205866\n",
      "Avg Kendall  corr value for df = 0.5484684661080166\n",
      "Epoch 4:\n",
      "Avg Spearman corr value for df = 0.7521419080544322\n",
      "Avg Kendall  corr value for df = 0.5946983833463781\n",
      "Epoch 5:\n",
      "Avg Spearman corr value for df = 0.7434892284569563\n",
      "Avg Kendall  corr value for df = 0.5861290246570876\n"
     ]
    }
   ],
   "source": [
    "for i in range(n_epoch):\n",
    "    print(f'Epoch {i+1}:')\n",
    "    validate(load_obj('test'), load_obj(f'em_weights_epoch_{i}'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Метрики не растут. В чем дело? Ход разбирательства:\n",
    "\n",
    "* Бейзлайн модель LogisticRegression, метрики падали сильнейшим образом, выяснил что данная модель из sklearn некорректно работает с небинарными таргетами, а именно они возникают на итерациях EM-алгоритм;\n",
    "* Заменил модель на LinearSVR, настроил параметры: метрики все также не растут, но хотя бы перестали убывать;\n",
    "* Заменил фичи m-step модели: (tournament_id, player_id) -> (player_id, question_id), по рост скачком выглядит подозрительно"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
